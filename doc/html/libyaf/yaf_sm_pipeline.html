<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<title>YAF - Documentation</title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />
        <link rel="stylesheet" type="text/css" href="doxygen.css">
        <link rel="stylesheet" type="text/css" href="../../site/style.css" />
        <link rel="stylesheet" type="text/css" href="tabs.css">
</head>
<body>
    <div id="p-body">
      <div id="l-header">
        <img src="../../site/sei-logo.png" id="l-sei-logo"
            alt="Software Engineering Institute | Carnegie Mellon&copy;" />
        <div id="l-netsa-logo"><a id="l-netsa-name" href="../../index.html"><b>CERT NetSA Security Suite</b></a></div>
        <div id="l-netsa-motto">Monitoring for Large-Scale Networks</div>
        <h1 class="l-page-title">YAF</h1>
        <span id="l-subtitle">Documentation</span>
      </div><!-- l-header -->
      <div id="l-content">
        <div id="l-sidebar">
          <div class="p-sidebar-section">
            <h1><a href="index.html">YAF</a></h1>
            <ul>
              <li><a href="../docs.html">Documentation</a></li>
              <li><a href="../download.html">Downloads</a></li>
            </ul>
          </div><!-- p-sidebar-section -->
        </div><!-- l-sidebar -->
      <div id="top"> <!-- need this for doxygen -->
<!-- Generated by Doxygen 1.8.11 -->
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Tutorials</span></a></li>
      <li><a href="annotated.html"><span>Data&#160;Structures</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Configuring YAF with super_mediator and Analysis Pipeline </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>This tutorial is a step-by-step guide of setting up <b>yaf</b>, <a href="http://tools.netsa.cert.org/super_mediator/index.html">super_mediator</a>, and <a href="http://tools.netsa.cert.org/analysis-pipeline5/index.html">Analysis Pipeline</a>.</p>
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#install">Basic Install</a></li>
<li><a href="#sm">Configure super_mediator</a></li>
<li><a href="#pipeline">Configure Analysis Pipeline</a></li>
<li><a href="#goyaf">Run YAF</a></li>
<li><a href="#analysis">DNS Baselining with Pipeline</a></li>
</ul>
<h1><a class="anchor" id="overview"></a>
Overview </h1>
<p>This tutorial explains the basics of setting up <b>yaf</b> to <b>super_mediator</b> to <b>pipeline</b>. It will also provide the configuration to implement DNS Baselining, an idea presented at the 2017 FloCon. The slides for the presentation, titled "Low Hanging Fruit Tastes Just As Good", can be found on the <a href="http://www.cert.org/flocon/index.cfm">FloCon web page</a>.</p>
<p>The idea behind DNS Baselining is if we create a list of all the domains seen on the network for some period of time, and if we're not already infected, malicious domains will be new at some point. Many attacks use recently registered domain names and the change in domain resolutions can be potentially interesting.</p>
<p><b>yaf</b> will be used to collect the DNS domain names. <b>super_mediator</b> will be used to de-duplicate the DNS domains and <b>pipeline</b> will be used to create the "whitelist" of DNS domains and then, after some period of time, will be used to alert when new domains are seen.</p>
<h1><a class="anchor" id="install"></a>
Install prerequisites </h1>
<p>$ yum groupinstall "Development Tools" $ yum install libpcap-devel pcre-devel</p>
<p>Build <a href="http://tools.netsa.cert.org/fixbuf/index.html">libfixbuf</a>: </p><pre class="fragment">$ tar -xvzf libfixbuf-1.7.1.tar.gz
$ cd libfixbuf-1.7.1
$ ./configure
$ make
$ make install
</pre><p>Build <b>yaf</b>: </p><pre class="fragment">$ tar -xvzf yaf-2.8.4.tar.gz
$ cd yaf-2.8.4
$ ./configure --enable-applabel --enable-plugins
$ make
$ make install
</pre><p>Build <b>super_mediator</b>: </p><pre class="fragment">$ tar -xvzf super_mediator-1.5.0.tar.gz
$ cd super_mediator-1.5.0
$ ./configure
$ make
$ make install
</pre><p>Build <a href="http://tools.netsa.cert.org/schemaTools/download.html">libschemaTools</a>: </p><pre class="fragment">$ tar -xvzf libschemaTools-1.2.1.tar.gz
$ cd libschemaTools
$ export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig
$ ./configure
$ make
$ make install
</pre><p>Build <a href="http://tools.netsa.cert.org/silk/index.html">SiLK</a>: </p><pre class="fragment">$ tar -xvzf silk-3.14.0.tar.gz
$ cd silk-3.14.0
$ ./configure --with-libfixbuf=/usr/local/lib/pkgconfig --enable-ipv6
$ make
$ make install
</pre><p>Build <a href="http://tools.netsa.cert.org/analysis-pipeline5/download.html">pipeline</a> </p><pre class="fragment">$ tar -xvzf analysis-pipeline-5.6.tar.gz
$ cd analysis-pipeline-5.6
$ export LD_LIBRARY_PATH=/usr/local/lib
$ ./configure --with-libsnarf=no --with-silk-config=/usr/local/bin/silk-config
$ make
$ make install
</pre><h1><a class="anchor" id="sm"></a>
Using super_mediator </h1>
<p>Create the file directories that <b>super_mediator</b> will use to write files that <b>pipeline</b> will process: </p><pre class="fragment">$ mkdir -p /data/pipeline/incoming/
</pre><p>Create your super_mediator.conf file. One is installed by default into /usr/local/etc. The following one will get you started: </p><pre class="fragment">COLLECTOR TCP "yaf"
   PORT 18000
COLLECTOR END

#dedup process
EXPORTER FILEHANDLER "dnsdedup"
   PATH "/data/pipeline/incoming/dns"
   REMOVE_EMPTY_FILES
   ROTATE 120
   DNS_DEDUP_ONLY
   LOCK
EXPORTER END

DNS_DEDUP "dnsdedup"
   RECORDS [1]
   MAX_HIT_COUNT 10000
   FLUSH_TIME 600
DNS_DEDUP END

LOGLEVEL DEBUG

LOG "/var/log/super_mediator.log"

PIDFILE "/data/super_mediator.pid"
</pre><p>Start <b>super_mediator</b>: </p><pre class="fragment">$ super_mediator -c /usr/local/etc/super_mediator.conf --daemonize
</pre><p>Confirm <b>super_mediator</b> is running: </p><pre class="fragment">$ ps -ef | grep super
</pre><p>If <b>super_mediator</b> is not running, check for any errors: </p><pre class="fragment">$ cat /var/log/super_mediator.log
</pre><h1><a class="anchor" id="pipeline"></a>
Configure Analysis Pipeline </h1>
<p>The first step is to build the whitelist of domain names, domain/IP pairs, unique second-level domains (SLDs) and unique SLDs + top-level domains (TLDs). The following <b>pipeline</b> configuration creates those 4 whitelists. </p><pre class="fragment">FILTER all
END FILTER

INTERNAL FILTER listBuilder
        FILTER all
        dnsQName sourceIPv4Address domainIPPairs 60 DAYS
        dnsQName domainList 60 DAYS
        DNS_SLD(dnsQName) slds 60 DAYS
        DNS_SLD+TLD(dnsQName) sldPlusTld 60 DAYS
END INTERNAL FILTER

LIST CONFIGURATION domainIPPairs
        UPDATE 5 MINUTES
        WRITE FILE WITHOUT ALERTING
        OUTPUT FILE "/data/pipeline/domainIPPairs.txt"
END LIST CONFIGURATION

LIST CONFIGURATION domainList
        UPDATE 5 MINUTES
        WRITE FILE WITHOUT ALERTING
        OUTPUT FILE "/data/pipeline/domainList.txt"
END LIST CONFIGURATION

LIST CONFIGURATION slds
        UPDATE 5 MINUTES
        WRITE FILE WITHOUT ALERTING
        OUTPUT FILE "/data/pipeline/slds.txt"
END LIST CONFIGURATION

LIST CONFIGURATION sldPlusTld
        UPDATE 5 MINUTES
        WRITE FILE WITHOUT ALERTING
        OUTPUT FILE "/data/pipeline/sldPlusTlds.txt"
END LIST CONFIGURATION
</pre><p>Running <b>pipeline</b>: </p><pre class="fragment">$ mkdir /data/pipeline/error

/usr/local/sbin/pipeline  \
--site-config-file=/data/silk.conf \
--alert-log-file=/data/pipeline/alertLog.txt \
--aux-alert-file=/data/pipeline/auxLog.txt \
--ipfix \
--time-field-name=flowStartMilliseconds \
--configuration=/data/pipeline/whitelists.conf \
--incoming-directory=/data/pipeline/incoming/ \
--error-directory=/data/pipeline/error \
--log-destination=syslog
</pre><h1><a class="anchor" id="goyaf"></a>
Start YAF </h1>
<pre class="fragment">$ mkdir /var/log/yaf

$ export LTDL_LIBRARY_PATH=/usr/local/lib/yaf
</pre><p>Example <b>yaf</b> command line for sniffing interface eth0: </p><pre class="fragment">/usr/local/bin/yaf
--in eth0 --live pcap \
--ipfix tcp \
--out localhost \
--log /var/log/yaf/yaf.log \
--verbose \
--silk \
--verbose \
--ipfix-port=18000 \
--applabel --max-payload 2048 \
--plugin-name=/usr/local/lib/yaf/dpacketplugin.so \
--plugin-opts="53"
</pre><h1><a class="anchor" id="analysis"></a>
DNS Baselining with Pipeline </h1>
<p>Once <b>pipeline</b> has been running for 4-6 weeks, sufficient whitelists have been created and it is time to restart <b>pipeline</b> with a configuration file that will use the whitelists to compare incoming domains against and alert when new domains seen. The whitelists will also be updated with the new domains so that <b>pipeline</b> only alerts when a domain is seen for the first time ever or when it has not been seen for over 60 days. </p><pre class="fragment">FILTER newDomains
        dnsQName NOT IN LIST "/data/pipeline/domainList.txt"
        dnsQName NOT IN LIST newestDomains
END FILTER

INTERNAL FILTER newestDomains
        FILTER newDomains
        dnsQName newestDomains 60 DAYS
END INTERNAL FILTER

EVALUATION newDomains
        FILTER newDomains
        CHECK EVERYTHING PASSES
        END CHECK
        ALERT ALWAYS
        ALERT EVERYTHING
END EVALUATION

FILTER newDomainsOnlyFile
        dnsQName NOT IN LIST "/data/pipeline/domainList.txt"
END FILTER

EVALUATION newDomainsOnlyFile
        FILTER newDomainsOnlyFile
        CHECK EVERYTHING PASSES
        END CHECK
        ALERT ALWAYS
        ALERT EVERYTHING
END EVALUATION

FILTER newIPForDomains
        dnsQName IN LIST "/data/pipeline/domainList.txt"
        sourceIPv4Address dnsQName NOT IN LIST "/data/pipeline/domainIPPairs.txt"
        sourceIPv4Address dnsQName NOT IN LIST newestDomainIPPairs
END FILTER

INTERNAL FILTER newestDomainIPPairs
        FILTER newIPForDomains
        sourceIPv4Address dnsQName newestDomainIPPairs 60 DAYS
END INTERNAL FILTER

EVALUATION newIPForDomains
        FILTER newIPForDomains
        CHECK EVERYTHING PASSES
        END CHECK
        ALERT ALWAYS
        ALERT EVERYTHING
END EVALUATION

FILTER newIPForDomainsOnlyFile
        dnsQName IN LIST "/data/pipeline/domainList.txt"
        sourceIPv4Address dnsQName NOT IN LIST "/data/pipeline/domainIPPairs.txt"
END FILTER

EVALUATION newIPForDomainsOnlyFile
        FILTER newIPForDomainsOnlyFile
        CHECK EVERYTHING PASSES
        END CHECK
        ALERT ALWAYS
        ALERT EVERYTHING
END EVALUATION

FILTER newSlds
        DNS_SLD(dnsQName) NOT IN LIST "/data/pipeline/slds.txt"
        DNS_SLD(dnsQName) NOT IN LIST newestSlds
END FILTER

INTERNAL FILTER newestSlds
        FILTER newSlds
        DNS_SLD(dnsQName) newestSlds 60 DAYS
END INTERNAL FILTER

EVALUATION newSlds
        FILTER newSlds
        CHECK EVERYTHING PASSES
        END CHECK
        ALERT ALWAYS
        ALERT EVERYTHING
END EVALUATION

FILTER newSldsOnlyFile
        DNS_SLD(dnsQName) NOT IN LIST "/data/pipeline/slds.txt"
END FILTER

EVALUATION newSldsOnlyFile
        FILTER newSldsOnlyFile
        CHECK EVERYTHING PASSES
        END CHECK
        ALERT ALWAYS
        ALERT EVERYTHING
END EVALUATION

FILTER newSLDplusTLD
        DNS_SLD+TLD(dnsQName) NOT IN LIST "/data/pipeline/sldPlusTlds.txt"
        DNS_SLD+TLD(dnsQName) NOT IN LIST newestSLDplusTLD
END FILTER

INTERNAL FILTER newestSLDplusTLD
        FILTER newSLDplusTLD
        DNS_SLD+TLD(dnsQName) newestSLDplusTLD 60 DAYS
END INTERNAL FILTER

EVALUATION newSLDplusTLD
        FILTER newSLDplusTLD
        CHECK EVERYTHING PASSES
        END CHECK
        ALERT ALWAYS
        ALERT EVERYTHING
END EVALUATION

FILTER newSLDplusTLDOnlyFile
        DNS_SLD+TLD(dnsQName) NOT IN LIST "/data/pipeline/sldPlusTlds.txt"
END FILTER

EVALUATION newSLDplusTLDOnlyFile
        FILTER newSLDplusTLD
        CHECK EVERYTHING PASSES
        END CHECK
        ALERT ALWAYS
        ALERT EVERYTHING
END EVALUATION
</pre><p>Remove old alert files and restart <b>pipeline</b>: </p><pre class="fragment">$ rm /data/pipeline/alertLog.txt
$ rm /data/pipeline/auxLog.txt

/usr/local/sbin/pipeline  \
--site-config-file=/data/silk.conf \
--alert-log-file=/data/pipeline/alertLog.txt \
--aux-alert-file=/data/pipeline/auxLog.txt \
--ipfix \
--time-field-name=flowStartMilliseconds \
--configuration=/data/pipeline/live_alert.conf \
--incoming-directory=/data/pipeline/incoming/ \
--error-directory=/data/pipeline/error \
--log-destination=syslog
</pre><p>The data will look similar to: </p><pre class="fragment">2017-01-31 20:19:16|Evaluation|newDomains|1|2016-12-01 00:01:01|216.239.34.102|1|ns-gce-public2.googledomains.com.|
2017-01-31 20:19:16|Evaluation|newDomains|1|2016-12-01 00:01:01|216.239.38.102|1|ns-gce-public4.googledomains.com.|
2017-01-31 20:19:16|Evaluation|newDomains|1|2016-12-01 00:01:01|216.239.36.102|1|ns-gce-public3.googledomains.com.|
2017-01-31 20:19:16|Evaluation|newDomains|1|2016-12-01 00:01:01|216.239.32.102|1|ns-gce-public1.googledomains.com.|
</pre><p><b>pipeline</b> will also allow you to filter out domains/SLDs/TLDs that are not of interest to you. That exercise will be left up to the reader. </p>
</div></div><!-- contents -->
      </div><!-- l-content -->
      <div id="l-footer">&copy; 2006-2016 Carnegie Mellon University</div>
    </div><!-- p-body -->
</body>
</html>   
